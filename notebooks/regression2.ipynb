{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deriving Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how to derive the least squares solution for multiple linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation\n",
    "Suppose you want to predict the vector $y$ using variables $x_1, x_2, \\dots, x_n$ stored as the columns of the design matrix $X$. This suggests the following model $ y = X\\beta + e $ where $\\beta$ denotes a vector of coefficients and $e$ denotes a vector of error terms not explained by the rest of the model (i.e., the residuals). Our goal is to determine the $\\beta$ values that minimize the sum of squared error. This approach is often called [*least squares*](https://en.wikipedia.org/wiki/Least_squares).\n",
    "* The error is simply $e = Xb$.\n",
    "* We want to find the $\\beta$ that minimizes $e \\cdot e = e'e = (y-X\\beta)'(y-X\\beta) = y'y - 2b'X'y + b'X'Xb$. \n",
    "* To mimimize, we take the derivative and set it equal to zero: $\\frac{\\partial(e \\cdot e)}{\\partial b} = -2X'y + 2X'Xb = 0$\n",
    "* Solving for $\\beta$ gives $X'Xb=X'y$ and finally $b=(X'X)^{-1}X'y$.\n",
    "\n",
    "Therefore, when trying to predict $y$ by $\\hat{y} = X\\hat{\\beta}$, our estimate for $\\beta$ should be $\\hat{\\beta} = (X'X)^{-1}X'y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load in the data using a [`Relation`](http://cobweb.cs.uga.edu/~jam/scalation_1.3/scalation_mathstat/target/scala-2.12/api/scalation/relalgebra/Relation$.html) to see what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scalation.linalgebra._\n",
    "val x = new MatrixD((8, 2), 1, 1.1, 2, 2.2, 3, 3.3, 4, 4.4, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val actual = VectorD(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val rng   = scalation.random.Normal(0, 0.01)           // random number generator\n",
    "val noise = VectorD(for (i <- x.range1) yield rng.gen) // make some noise\n",
    "val y     = (x * actual) + noise                       // make noisy response vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val b = (x.t * x).inverse * x.t * y\n",
    "val e = y - x * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val sse = e dot e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScalaTion",
   "language": "scala",
   "name": "scalation"
  },
  "language_info": {
   "file_extension": ".scala",
   "mimetype": "text/x-scala-source",
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
